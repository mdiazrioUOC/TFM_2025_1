{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO ontology loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import tqdm \n",
    "import json\n",
    "import chromadb\n",
    "import voyageai\n",
    "import pickle as pkl\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "VOYAGE_API_KEY = os.getenv(\"VOYAGE_API_KEY\")\n",
    "RESOURCES_DIR=\"../../resources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESOURCES_DIR, \"hpo_es.json\"), \"r\") as fp:\n",
    "    hpo = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the desired fields of the ontology\n",
    "fields = [\"esp_name\", \"esp_def\", 'esp_synonyms', \"is_a\"]\n",
    "hpo_dict = {}\n",
    "\n",
    "for element in hpo:\n",
    "    hpo_dict[element[\"id\"]] = {field:element[field] for field in fields if field in element}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total docs: 19077\n",
      "Total elements with a spanish name: 19077\n",
      "Total elements with a spanish definition: 16504\n",
      "Total elements with a spanish synonym: 10852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def_count = 0\n",
    "name_count = 0\n",
    "synonym_count = 0\n",
    "for k,v in hpo_dict.items():\n",
    "    if \"esp_def\" in v:\n",
    "        def_count += 1\n",
    "    if \"esp_name\" in v:\n",
    "        name_count += 1\n",
    "    if \"esp_synonyms\" in v:\n",
    "        synonym_count += 1\n",
    "\n",
    "print(f\"\"\"Total docs: {len(hpo_dict)}\n",
    "Total elements with a spanish name: {name_count}\n",
    "Total elements with a spanish definition: {def_count}\n",
    "Total elements with a spanish synonym: {synonym_count}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesar linaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lineage(s):\n",
    "    return s.split('!')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean lineage\n",
    "for k,v in hpo_dict.items():\n",
    "    if \"is_a\" in v:\n",
    "        if isinstance(v[\"is_a\"], list):\n",
    "            for i, parent in enumerate(v[\"is_a\"]):\n",
    "                v[\"is_a\"][i] = clean_lineage(parent)\n",
    "        else:\n",
    "            v[\"is_a\"] = clean_lineage(v[\"is_a\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean lineage\n",
    "def find_parent(hpo_code, hpo_dict=hpo_dict):\n",
    "    lineage = hpo_dict[hpo_code][\"is_a\"]\n",
    "    if isinstance(lineage, list):\n",
    "        parents = set(lineage)\n",
    "        for parent in lineage:\n",
    "            parents.update(find_parent(parent))\n",
    "        return parents\n",
    "    \n",
    "    if \"is_a\" not in hpo_dict[lineage]:\n",
    "        return []\n",
    "    \n",
    "    return [lineage] + list(find_parent(lineage))\n",
    "    \n",
    "\n",
    "_ = {v.update({\"lineage\": find_parent(k)}) for k,v in hpo_dict.items() if \"is_a\" in v}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating info for chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_names_dict(terms, hpo_code, names_dict):\n",
    "    for term in terms:\n",
    "        term = term.lower()\n",
    "        if term in names_dict and hpo_code not in names_dict[term]:\n",
    "            names_dict[term] += [hpo_code]\n",
    "        else:\n",
    "            names_dict[term] = [hpo_code]\n",
    "    return names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_text = []\n",
    "metadata_list = []\n",
    "names_dict = {}\n",
    "for hpo_code, hpo_values in hpo_dict.items():\n",
    "    metadata = {\"hpo_id\":hpo_code}\n",
    "    cleaned_info = []\n",
    "    if \"esp_name\" in hpo_values:\n",
    "        cleaned_info.append(hpo_values[\"esp_name\"])\n",
    "        names_dict = add_to_names_dict([hpo_values[\"esp_name\"]], hpo_code, names_dict)\n",
    "    if \"esp_synonyms\" in hpo_values:\n",
    "        syn_list = hpo_values[\"esp_synonyms\"] if isinstance (hpo_values[\"esp_synonyms\"], list) else [hpo_values[\"esp_synonyms\"]]\n",
    "        syn_list = [str(s) for s in syn_list]\n",
    "        cleaned_info += syn_list\n",
    "        names_dict = add_to_names_dict(syn_list, hpo_code, names_dict)\n",
    "    if \"esp_def\" in hpo_values:\n",
    "        cleaned_info.append(hpo_values[\"esp_def\"])\n",
    "    cleaned_info = [str(s) for s in cleaned_info]\n",
    "    # if \"esp_synonyms\" in hpo_values:\n",
    "    #     cleaned_info + hpo_values[\"synonyms\"]\n",
    "    cleaned_info = [s.strip() + \".\" if not s.strip().endswith(\".\") else s.strip() for s in cleaned_info]\n",
    "    cleaned_info = \" \".join(cleaned_info)\n",
    "    documents_text.append(cleaned_info)\n",
    "    if \"lineage\" in hpo_values:\n",
    "        metadata[\"lineage\"] = \"->\".join(hpo_values[\"lineage\"])\n",
    "    metadata_list.append(metadata)\n",
    "ids_list = [v['hpo_id'] for v in metadata_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Voyage Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"BAAI/bge-small-en-v1.5\"\n",
    "MODEL_NAME = \"voyage-3\"\n",
    "\n",
    "# embeddings = FastEmbedEmbeddings(model_name=MODEL_NAME)\n",
    "embeddings_model = VoyageAIEmbeddings(voyage_api_key=VOYAGE_API_KEY,model=\"voyage-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 150/150 [51:56<00:00, 20.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# vo = voyageai.Client(api_key=VOYAGE_API_KEY)\n",
    "\n",
    "# batch_size = 50\n",
    "# tokens=0\n",
    "# starttime = time.time()\n",
    "\n",
    "# for i in tqdm.tqdm(range(len(embeddings), len(documents_text), batch_size), desc=\"Batch: \" ):       \n",
    "#     if tokens >= 9000:\n",
    "#         while time.time() < starttime + 61:\n",
    "#             time.sleep(1)\n",
    "#         tokens = 0\n",
    "#         starttime = time.time()\n",
    "\n",
    "#     response= vo.embed(\n",
    "#         documents_text[i:i + batch_size], model=MODEL_NAME, input_type=\"document\"\n",
    "#     )\n",
    "#     tokens += response.total_tokens \n",
    "#     embeddings += response.embeddings\n",
    "\n",
    "#     time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 20/20 [00:37<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "vo = voyageai.Client(api_key=VOYAGE_API_KEY)\n",
    "batch_size = 1000\n",
    "embeddings= []\n",
    "for i in tqdm.tqdm(range(len(embeddings), len(documents_text), batch_size), desc=\"Batch: \" ):       \n",
    "    response= vo.embed(\n",
    "        documents_text[i:i + batch_size], model=MODEL_NAME, input_type=\"document\"\n",
    "    )\n",
    "    embeddings += response.embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19533"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../resources/Voyage Embeddings/docs_w_synonyms.pkl\", \"wb\") as fp:\n",
    "    pkl.dump({\"ids\": ids_list, \"docs\":documents_text}, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../resources/Voyage Embeddings/embeddings_w_synonyms.pkl\", \"wb\") as fp:\n",
    "    pkl.dump(embeddings, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"embeddings_w_synonyms.pkl\", \"rb\") as fp:\n",
    "    embeddings = pkl.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs.pkl\", \"rb\") as fp:\n",
    "    docs = pkl.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"../../chroma_db/Voyage3\")\n",
    "collection = chroma_client.get_or_create_collection(\"hpo_ontology_esp_FULL\")\n",
    "collection.add(\n",
    "        embeddings=embeddings,\n",
    "        documents=documents_text,\n",
    "        metadatas=metadata_list,\n",
    "        ids=ids_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../resources/names_dict.pkl\", \"wb\") as fp:\n",
    "    pkl.dump(names_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_chroma = Chroma(\n",
    "    client=chroma_client,\n",
    "    collection_name=\"hpo_ontology_esp_FULL\",\n",
    "    embedding_function=embeddings_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19533 documents in the collection\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", langchain_chroma._collection.count(), \"documents in the collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=\"../../chroma_db/Voyage3\", embedding_function=embeddings_model, \n",
    "                  collection_name=\"hpo_ontology_esp_FULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.as_retriever(search_kwargs= \"where_document={'$contains':'mareos'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='HP:0008738', metadata={'hpo_id': 'HP:0008738', 'lineage': 'HP:0000075->HP:0001438->HP:0000077->HP:0000119->HP:0000118->HP:0010935->HP:0005217->HP:0025031->HP:0000079->HP:0012210'}, page_content='Riñón parcialmente duplicado. La presencia de un riñón parcialmente duplicado.'),\n",
       " Document(id='HP:0430044', metadata={'hpo_id': 'HP:0430044', 'lineage': 'HP:0012836->HP:0012830->HP:0012823'}, page_content='Radiación en el brazo izquierdo. Se refiere a un dolor o molestia que se percibe desde el pecho hacia el brazo izquierdo.'),\n",
       " Document(id='HP:0012784', metadata={'hpo_id': 'HP:0012784', 'lineage': 'HP:0000123->HP:0011277->HP:0000077->HP:0010978->HP:0012211->HP:0000119->HP:0002715->HP:0010935->HP:0012647->HP:0012649->HP:0000118->HP:0000079'}, page_content='Perinefritis. Inflamación de los tejidos conjuntivo y adiposo que rodean al riñón.'),\n",
       " Document(id='HP:0011126', metadata={'hpo_id': 'HP:0011126', 'lineage': 'HP:0100542->HP:0012210->HP:0000077->HP:0010935->HP:0000079->HP:0000119->HP:0000118'}, page_content='Nefroptosis. Descenso significativo del riñón cuando el paciente pasa de la posición supina a la erecta.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.max_marginal_relevance_search(\"Tiene dolor en el riñon izquierdo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25 Retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs_list = []\n",
    "for id, metadata, page_content in zip(ids_list, metadata_list, documents_text):\n",
    "    docs_list.append(Document(id=id, metadata=metadata, page_content=page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "keyword_retriever = BM25Retriever.from_documents(docs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19077"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keyword_retriever.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(retrievers=[vectordb.as_retriever(),\n",
    "                                                   keyword_retriever],\n",
    "                                       weights=[0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../resources/keyword_retriever.pkl\", 'wb') as fp:\n",
    "    pkl.dump(keyword_retriever, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
