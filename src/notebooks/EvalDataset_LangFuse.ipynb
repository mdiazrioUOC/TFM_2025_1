{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the evaluation Dataset with Langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re \n",
    "from datetime import datetime\n",
    "import json\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langsmith import Client, evaluate\n",
    "from phenopy.score import Scorer\n",
    "from langsmith.schemas import Run, Example\n",
    "from phenopy.build_hpo import generate_annotated_hpo_network\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "\n",
    "import customchain as cc\n",
    "custom_chain = cc.custom_chain\n",
    "\n",
    "import rawgptchain as rgc\n",
    "rawgptchain = rgc.rawgptchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de los datasets de RAG-HPO y GSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    " \n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id='cm9x6ivv80096pf0604is8yzj', name='RAGHPO', description='Dataset en español para la evaluación de herramientas de codificación fenotípica.', metadata={'date': '2025-04-25', 'type': 'benchmark', 'author': 'mdiazrio'}, project_id='cm9vlvsif0006pf07xcychmbe', created_at=datetime.datetime(2025, 4, 25, 19, 23, 13, 748000, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 4, 25, 19, 23, 13, 748000, tzinfo=datetime.timezone.utc))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse.create_dataset(\n",
    "    name=\"RAGHPO\",\n",
    "    # optional description\n",
    "    description=\"Dataset en español para la evaluación de herramientas de codificación fenotípica.\",\n",
    "    # optional metadata\n",
    "    metadata={\n",
    "        \"author\": \"mdiazrio\",\n",
    "        \"date\": \"2025-04-25\",\n",
    "        \"type\": \"benchmark\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/RAG-HPO/Test_Cases.csv')\n",
    "df[\"annotations\"] = df.annotations.apply(eval)\n",
    "df = df.rename(columns={'esp':'clinical_note'})\n",
    "input_keys = ['clinical_note']\n",
    "output_keys = ['annotations'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCES_DIR=\"../../resources\"\n",
    "with open(os.path.join(RESOURCES_DIR, \"hpo_es.json\"), \"r\") as fp:\n",
    "    hpo = json.load(fp)\n",
    "valid_ids = [x['id'] for x in hpo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output(output):\n",
    "    hpo_list = [s.strip() for s in output]\n",
    "    hpo_list = [j for j in hpo_list if re.compile(r\"^HP:\\d{7}$\").match(j)]\n",
    "    hpo_list = [i for i in hpo_list if i in valid_ids]\n",
    "    return {\"annotations\":hpo_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows(): \n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=\"RAGHPO\",\n",
    "        input={\"clinical_note\": row['clinical_note']},\n",
    "        expected_output=process_output(row['annotations'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GSCESP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(id='cm9xwlj4n015vpf06u8x2xkjn', name='GSCESP', description='Dataset en español para la evaluación de herramientas de codificación fenotípica.', metadata={'date': '2025-04-26', 'type': 'benchmark', 'author': 'mdiazrio'}, project_id='cm9vlvsif0006pf07xcychmbe', created_at=datetime.datetime(2025, 4, 26, 7, 33, 7, 223000, tzinfo=datetime.timezone.utc), updated_at=datetime.datetime(2025, 4, 26, 7, 33, 7, 223000, tzinfo=datetime.timezone.utc))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langfuse.create_dataset(\n",
    "    name=\"GSCESP\",\n",
    "    # optional description\n",
    "    description=\"Dataset en español para la evaluación de herramientas de codificación fenotípica.\",\n",
    "    # optional metadata\n",
    "    metadata={\n",
    "        \"author\": \"mdiazrio\",\n",
    "        \"date\": \"2025-04-26\",\n",
    "        \"type\": \"benchmark\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "annotations = []\n",
    "for file in os.listdir(\"../../datasets/GCS+_ESP/Text\"):\n",
    "    with open(os.path.join(\"../../datasets/GCS+_ESP/Text\", file), \"r\") as fp:\n",
    "        texts.append(fp.read())\n",
    "    annots = pd.read_csv(os.path.join(\"../../datasets/GSC+/Annotations\", file), header=None, sep=\"\\t\")\n",
    "    annots[1] = annots[1].apply(lambda x: x.split(\"|\")[0].strip())\n",
    "    annotations.append(annots[1].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_esp = pd.DataFrame({\"esp\":texts, \"annotations\":annotations})\n",
    "gcs_esp.rename(columns={\"esp\":\"clinical_note\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_output(output):\n",
    "    hpo_list = [s.strip() for s in output]\n",
    "    hpo_list = [s.replace('_', ':') for s in hpo_list]\n",
    "    hpo_list = [j for j in hpo_list if re.compile(r\"^HP:\\d{7}$\").match(j)]\n",
    "    hpo_list = [i for i in hpo_list if i in valid_ids]\n",
    "    hpo_list = list(set(hpo_list))\n",
    "    return {\"annotations\":hpo_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in gcs_esp.iterrows(): \n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=\"GSCESP\",\n",
    "        input={\"clinical_note\": row['clinical_note']},\n",
    "        expected_output=process_output(row['annotations'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definición de las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_final_answer(outputs):\n",
    "    try:\n",
    "        return [code.hpo_code.strip() for code in outputs[\"final answer\"]]\n",
    "    except:\n",
    "        return outputs[\"final answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenopy_data_directory = \"../../resources/\"\n",
    "\n",
    "# files used in building the annotated HPO network\n",
    "obo_file = os.path.join(phenopy_data_directory, 'hp.obo')\n",
    "disease_to_phenotype_file = os.path.join(phenopy_data_directory, 'phenotype.hpoa')\n",
    "\n",
    "hpo_network, alt2prim, disease_records = \\\n",
    "    generate_annotated_hpo_network(obo_file,\n",
    "                                   disease_to_phenotype_file)\n",
    "\n",
    "scorer = Scorer(hpo_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can still pass in Run and Example objects if we'd like\n",
    "def traditional_metrics(outputs: dict, reference_outputs: dict) -> list[dict]:\n",
    "    \"\"\"Check precision, recall and f1.\"\"\"\n",
    "    predicted_terms = clean_final_answer(outputs)\n",
    "    real_terms = reference_outputs[\"annotations\"]\n",
    "    precision = 0 if len(predicted_terms) == 0 else sum([int(term in real_terms) for term in predicted_terms]) / len(predicted_terms)\n",
    "    recall = 0 if len(real_terms) == 0 else sum([int(term in predicted_terms) for term in real_terms]) / len(real_terms)\n",
    "    f1 = 0 if (precision + recall) == 0 else round(2 * (precision * recall) / (precision + recall),2)\n",
    "\n",
    "    return [\n",
    "        {\"key\": \"precision\", \"score\": precision},\n",
    "        {\"key\": \"recall\", \"score\": recall},\n",
    "        {\"key\": \"f1\", \"score\": f1},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarity(outputs: dict, reference_outputs: dict)->float:\n",
    "    \"\"\"Check semantic similarity using phenopy.\"\"\"\n",
    "    predicted_terms = clean_final_answer(outputs)\n",
    "    real_terms = reference_outputs[\"annotations\"]\n",
    "    try:\n",
    "        score = scorer.score_term_sets_basic(predicted_terms, real_terms)\n",
    "    except:\n",
    "        score = -1\n",
    "    return [{\"key\": \"semantic similarity\", \"score\":score }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(outputs: dict, reference_outputs: dict)->float:\n",
    "    \"\"\"Check Jaccard similarity between two sets.\"\"\"\n",
    "    predicted_terms = set(clean_final_answer(outputs))\n",
    "    real_terms = set(reference_outputs[\"annotations\"])   \n",
    "    intersection = predicted_terms.intersection(real_terms)\n",
    "    union = predicted_terms.union(real_terms)\n",
    "    if not union:\n",
    "        return 1.0  # define similarity as 1.0 when both are empty\n",
    "    return [{\"key\": \"jaccard_similarity\", \"score\": len(intersection) / len(union)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_accuracy(outputs: dict, reference_outputs: dict)->float:\n",
    "    \"\"\"Check retriever accuracy and recall.\"\"\"\n",
    "    predicted_candidates = set().union(*outputs[\"docs\"])\n",
    "    real_terms = set(reference_outputs[\"annotations\"])\n",
    "    recall = len(real_terms & predicted_candidates) / len(real_terms)           # = 2/2 = 1.0\n",
    "    precision = len(real_terms & predicted_candidates) / len(predicted_candidates)   \n",
    "\n",
    "    return [{\"key\": \"r_precision\", \"score\": precision}, \n",
    "            {\"key\": \"r_recall\", \"score\": recall}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(rgc)\n",
    "rawgptchain = rgc.rawgptchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malenadiazrio/Documents/UOC/TFM/TFM_2025_1/.venv/lib/python3.11/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/Users/malenadiazrio/Documents/UOC/TFM/TFM_2025_1/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "dataset = langfuse.get_dataset(\"RAGHPO\")\n",
    "evaluators = [traditional_metrics, semantic_similarity, jaccard_similarity] \n",
    "run_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "for item in dataset.items:\n",
    "    try:\n",
    "        handler = item.get_langchain_handler(run_name=run_name)\n",
    "        response = rawgptchain.with_config({ \"callbacks\": [handler]}).invoke(item.input)\n",
    "        for evaluator in evaluators:\n",
    "            scores = evaluator(response, item.expected_output)\n",
    "            for score in scores:\n",
    "                langfuse.score(trace_id=handler.get_trace_id(), name=score[\"key\"], value=score[\"score\"])\n",
    "    except:\n",
    "        continue\n",
    "# Flush the langfuse client to ensure all data is sent to the server at the end of the experiment run\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "embeddings_model = VoyageAIEmbeddings(model=\"voyage-3\")\n",
    "vectordb = Chroma(persist_directory=\"../../chroma_db/Voyage3\", embedding_function=embeddings_model, \n",
    "                  collection_name=\"hpo_ontology_esp\")\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='HP:0001539', metadata={'hpo_id': 'HP:0001539', 'lineage': 'HP:0004299->HP:0003549->HP:0033127->HP:0010866->HP:0000118->HP:0004298->HP:0025031->HP:0100790'}, page_content='Hernia umbilical. Cierre incompleto anterior de la línea media de la pared abdominal en el que hay herniación de las vísceras abdominales hacia la base de la cuerda abdominal.'),\n",
       " Document(id='HP:0001973', metadata={'hpo_id': 'HP:0001973', 'lineage': 'HP:0002960->HP:0011875->HP:0002715->HP:0001873->HP:0001872->HP:0000118->HP:0011873->HP:0010978->HP:0001871'}, page_content='Trombocitopenia autoinmune. La presencia de trombocitopenia en combinación con la detección de anticuerpos antiplaquetarios.'),\n",
       " Document(id='HP:0009738', metadata={'hpo_id': 'HP:0009738', 'lineage': 'HP:0000377->HP:0000356->HP:0031703->HP:0000598->HP:0000118'}, page_content='Anomalía del antihelix. Una anomalía de la antihélice.'),\n",
       " Document(id='HP:0010184', metadata={'hpo_id': 'HP:0010184', 'lineage': 'HP:0010161->HP:0001780->HP:0011297->HP:0040064->HP:0000924->HP:0040068->HP:0001760->HP:0011842->HP:0011844->HP:0002813->HP:0000118->HP:0033127->HP:0002814'}, page_content='Anomalía de falange proximal del dedo del pie. Anomalía morfológica de una o varias falanges proximales de uno o varios dedos del pie.'),\n",
       " Document(id='HP:0100665', metadata={'hpo_id': 'HP:0100665', 'lineage': 'HP:0001626->HP:0000951->HP:0012337->HP:0011032->HP:0000969->HP:0001574->HP:0011276->HP:0002597->HP:0001939->HP:0000118->HP:0011354->HP:0011121'}, page_content='Angioedema. Hinchazón rápida (edema) de la dermis, el tejido subcutáneo, la mucosa y los tejidos submucosos de la piel de la cara, normalmente alrededor de la boca, y la mucosa de la boca y/o garganta, así como la lengua durante un periodo de minutos a varias horas. La hinchazón también puede producirse en otros lugares, normalmente en las manos. El angioedema es similar a la urticaria, pero la hinchazón es subcutánea y no en la epidermis.')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.get_by_ids(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../datasets/TFM_test.csv\")\n",
    "test_df.annotations = test_df.annotations.apply(eval)\n",
    "clinical_note = test_df.texts.iloc[0]\n",
    "hpo_codes = test_df.annotations.iloc[0]\n",
    "codigos_reales = {doc.id:doc.page_content for doc in  vectordb.get_by_ids(set(hpo_codes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HP:0001513': 'Obesidad. Acumulación de un exceso considerable de grasa corporal.',\n",
       " 'HP:0004394': 'Pólipos gástricos múltiples.',\n",
       " 'HP:0005227': 'Poliposis colónica adenomatosa. Presencia de múltiples pólipos adenomatosos en el colon.',\n",
       " 'HP:0012183': 'Poliposis colónica hiperplásica. Presencia de múltiples pólipos hiperplásicos en el colon. Los pólipos hiperplásicos suelen tener un tamaño de unos 5 mm y muestran una proliferación hiperplásica de la mucosa.',\n",
       " 'HP:0025501': 'Obesidad clase III. Obesidad con un índice de masa corporal de 40 kg por metro cuadrado o superior.',\n",
       " 'HP:0031500': 'Masa abdominal. Agrandamiento o hinchazón anormal del abdomen.',\n",
       " 'HP:0033769': 'Poliposis de las glándulas fúndicas. Múltiples pólipos en la mucosa secretora de ácido del cuerpo gástrico y el fundus. Los pólipos de la glándula fúndica (PGF) suelen tener un tamaño de 1 a 5 mm, aunque se han encontrado pólipos de mayor tamaño. Suelen ser sésiles, brillantes, translúcidos, de color pálido a rosado (parecido al de la mucosa circundante) y a menudo presentan pequeños vasos sanguíneos superficiales. Se ha observado que, a diferencia de otros tipos de pólipos gástricos, estos pólipos se astillan o se desprenden por completo de la base cuando se extraen con pinzas frías.',\n",
       " 'HP:0100580': 'Esófago de Barrett. Cambio anormal (metaplasia) en las células de la porción inferior del esófago. El epitelio escamoso normal que recubre el esófago es sustituido por epitelio columnar metaplásico. El epitelio columnar es un tipo de célula que suele encontrarse en las partes más distales del sistema gastrointestinal.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codigos_reales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
