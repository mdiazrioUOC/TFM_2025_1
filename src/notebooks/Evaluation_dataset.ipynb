{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import deepl\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "DEEPL_API_KEY = os.getenv(\"DEEPL_API_KEY\")\n",
    "translator = deepl.Translator(DEEPL_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCS Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_folder = \"../../datasets/GSC+/Annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_hpo_codes = set()\n",
    "for file in os.listdir(annotations_folder)[1:]:\n",
    "    df = pd.read_csv(os.path.join(annotations_folder, file), sep=r\"[\\t|]\", header=None, names=[\"positions\", \"hpo_code\", \"hpo_name\"], engine='python')\n",
    "    evaluation_hpo_codes.update(df.hpo_code.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_folder = \"../../datasets/GSC+/Text\"\n",
    "text_content = {}\n",
    "total_chars = 0\n",
    "for file_name in os.listdir(text_folder):\n",
    "     with open(os.path.join(text_folder, file_name), \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "            content = file.read()\n",
    "            total_chars += len(content)\n",
    "            text_content[file_name] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el número de ids en chunks de 50\n",
    "def chunk_dict_keys(d, chunk_size=50):\n",
    "    values = list(d.keys())  \n",
    "    return [values[i:i + chunk_size] for i in range(0, len(values), chunk_size)]\n",
    "\n",
    "chunks = chunk_dict_keys(text_content, chunk_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chunks_to_json(chunks, filename=\"chunks.json\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(chunks, file, indent=4)\n",
    "\n",
    "def load_chunks_from_json(filename=\"chunks.json\"):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        chunks = json.load(file)  # Load JSON into a Python list\n",
    "    return chunks\n",
    "\n",
    "save_chunks_to_json(chunks, \"../../resources/evalGCS+_chunks.json\")\n",
    "chunks = load_chunks_from_json(\"../../resources/evalGCS+_chunks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../../datasets/GCS+_ESP/Text\"):\n",
    "    os.makedirs(\"../../datasets/GCS+_ESP/Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There eval dataset has 226191 characters in total\n"
     ]
    }
   ],
   "source": [
    "print(f\"There eval dataset has {total_chars} characters in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_txt(ids, traducciones, dir):\n",
    "    for id, traduccion in zip(ids, traducciones):\n",
    "        with open(os.path.join(dir, id), \"w\") as fp:\n",
    "            fp.write(traduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for _ in tqdm(range(1), desc=\"Traduciendo\"):\n",
    "    processed_codes = os.listdir(\"../../datasets/GCS+_ESP/Text\")\n",
    "    for i in range(len(chunks)):\n",
    "        if all([s in processed_codes for s in chunks[i]]):\n",
    "            continue\n",
    "        break\n",
    "    if i == len(chunks):\n",
    "        break\n",
    "    texto_original = [text_content[j] for j in chunks[i]]\n",
    "    idioma_destino = \"ES\"  # Código de idioma (ES = español, EN = inglés, etc.)\n",
    "\n",
    "    traduccion = translator.translate_text(texto_original, target_lang=idioma_destino)\n",
    "    texto_traduccion = [t.text for t in traduccion]\n",
    "\n",
    "    save_to_txt(chunks[i], texto_traduccion, \"../../datasets/GCS+_ESP/Text\")  # Guarda en \"output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compruebo que se han traducido todos los archivos\n",
    "og_files = os.listdir(\"../../datasets/GSC+/Text\")\n",
    "esp_files = os.listdir(\"../../datasets/GCS+_ESP/Text\")\n",
    "set(og_files) - set(esp_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG-HPO Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>eng</th>\n",
       "      <th>esp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,</td>\n",
       "      <td>A 44-year- old super-morbidly- obese man body ...</td>\n",
       "      <td>Un hombre de 44 años con obesidad mórbida e ín...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2,</td>\n",
       "      <td>A 32-year-old man presented to a regional gene...</td>\n",
       "      <td>Un hombre de 32 años acudió a una unidad regio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3,</td>\n",
       "      <td>In December 1990, a 24-year-old female was ref...</td>\n",
       "      <td>En diciembre de 1990, una mujer de 24 años fue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                eng  \\\n",
       "0  1,  A 44-year- old super-morbidly- obese man body ...   \n",
       "1  2,  A 32-year-old man presented to a regional gene...   \n",
       "2  3,  In December 1990, a 24-year-old female was ref...   \n",
       "\n",
       "                                                 esp  \n",
       "0  Un hombre de 44 años con obesidad mórbida e ín...  \n",
       "1  Un hombre de 32 años acudió a una unidad regio...  \n",
       "2  En diciembre de 1990, una mujer de 24 años fue...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"../../datasets/Test_Cases.xlsx\")\n",
    "df.columns  = [\"id\", \"eng\", \"esp\"]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos no traducidos: 82\n",
      "Caracteres a traducir: 155294\n"
     ]
    }
   ],
   "source": [
    "print(f\"Documentos no traducidos: {df[df.esp.isna()].shape[0]}\") \n",
    "print(f\"Caracteres a traducir: {sum(df[df.esp.isna()].eng.apply(lambda x: len(x)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "while df[df.esp.isna()].shape[0] > 0:\n",
    "    texto_original = df[df.esp.isna()].iloc[0:10].eng.to_list()\n",
    "    idxs = df[df.esp.isna()].iloc[0:10].index\n",
    "    idioma_destino = \"ES\"  # Código de idioma (ES = español, EN = inglés, etc.)\n",
    "    traduccion = translator.translate_text(texto_original, target_lang=idioma_destino)\n",
    "    texto_traduccion = [t.text for t in traduccion]\n",
    "    df.loc[idxs, \"esp\"] = texto_traduccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.id = df.id.apply(lambda x: int(x[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../datasets/RAG-HPO/Test_Cases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 4)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = pd.read_csv(\"../../datasets/RAG-HPO/Test_Cases.csv\")\n",
    "eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura y asociación de los textos con sus anotaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../../datasets/RAG-HPO/RAG-HPO_Tests_and_Data_Analysis.xlsx\", header=None)\n",
    "df = df[[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pd.isna(df.loc[3099][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = {}\n",
    "id = None\n",
    "read = False\n",
    "for i, row in df.iterrows():\n",
    "    if pd.isna(row[2]):\n",
    "        read=False\n",
    "    if row[1] == \"Manually Assigned HPO Terms\":\n",
    "        if id is not None:\n",
    "            annotations[id] = annot_list\n",
    "        id = None\n",
    "        annot_list = []\n",
    "        read=True\n",
    "        if not pd.isna(row[0]) and row[0]!=\"Case\":\n",
    "            id = row[0] + 96\n",
    "\n",
    "    if read and row[1] == \"Phenotype name\" and id is None:\n",
    "        if row[0] == \"Case\":\n",
    "            id = df.loc[i+1, 0]\n",
    "        else:\n",
    "            id = row[0]\n",
    "\n",
    "    if read and isinstance(row[2], str) and row[2] not in ['none', 'HPO ID']:\n",
    "        annot_list.append(row[2])\n",
    "annotations[id] = annot_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HP:0000832',\n",
       " 'HP:0000988',\n",
       " 'HP:0001000',\n",
       " 'HP:0001880',\n",
       " 'HP:0001974',\n",
       " 'HP:0002728',\n",
       " 'HP:0002925',\n",
       " 'HP:0004322',\n",
       " 'HP:0005407',\n",
       " 'HP:0010280',\n",
       " 'HP:0010783',\n",
       " 'HP:0025092',\n",
       " 'HP:0031392',\n",
       " 'HP:0031446',\n",
       " 'HP:0031507',\n",
       " 'HP:0032210',\n",
       " 'HP:0033078',\n",
       " 'HP:0033425',\n",
       " 'HP:0040189',\n",
       " 'HP:0045080',\n",
       " 'HP:0100643',\n",
       " 'HP:0100827',\n",
       " 'HP:0200041',\n",
       " 'HP:0025697']"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[104]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"../../resources\", \"hpo_es.json\"), \"r\") as fp:\n",
    "    hpo = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the desired fields of the ontology\n",
    "fields = [\"esp_name\", \"esp_def\", \"is_a\"]\n",
    "hpo_dict = {}\n",
    "\n",
    "for element in hpo:\n",
    "    hpo_dict[element[\"id\"]] = {field:element[field] for field in fields if field in element}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'esp_name': 'Hipotiroidismo primario',\n",
       " 'esp_def': 'Tipo de hipotiroidismo que resulta de un defecto en la glándula tiroides.',\n",
       " 'is_a': 'HP:0000821 ! Hypothyroidism'}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpo_dict['HP:0000832']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                                  103\n",
      "id                                                          104\n",
      "eng            A young girl in her early childhood was refer...\n",
      "esp            Una niña de corta edad fue remitida a nuestra...\n",
      "Name: 103, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"../../datasets/RAG-HPO/Test_Cases.csv\")\n",
    "print(test.loc[103])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns = \"Unnamed: 0\", inplace=True)\n",
    "test[\"annotations\"] = test.id.apply(lambda x: annotations[x])\n",
    "test.to_csv(\"../../datasets/RAG-HPO/Test_Cases.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectura y asociación de términos del GSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "annotations = []\n",
    "for file in os.listdir(\"../../datasets/GCS+_ESP/Text\"):\n",
    "    with open(os.path.join(\"../../datasets/GCS+_ESP/Text\", file), \"r\") as fp:\n",
    "        texts.append(fp.read())\n",
    "    annots = pd.read_csv(os.path.join(\"../../datasets/GSC+/Annotations\", file), header=None, sep=\"\\t\")\n",
    "    annots[1] = annots[1].apply(lambda x: x.split(\"|\")[0].strip())\n",
    "    annotations.append(annots[1].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenación de ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((116, 4), (228, 2))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = test[[\"esp\", \"annotations\"]]\n",
    "final_test= final_test.rename(columns={\"esp\":\"texts\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = pd.concat([final_test, test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test.to_csv(\"../../datasets/TFM_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
